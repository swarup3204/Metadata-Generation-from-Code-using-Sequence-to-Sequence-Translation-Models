{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metadata Generation from Code using Sequence to Sequence Translation Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WU5TZHo1msXqVAJxWR2ar8Xm-1jZMQwc",
      "authorship_tag": "ABX9TyMhni3E3CI8vM+WSiQIfVYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarup3204/Metadata-Generation-from-Code-using-Sequence-to-Sequence-Translation-Models/blob/main/Metadata_Generation_from_Code_using_Sequence_to_Sequence_Translation_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Release and Pre Processing."
      ],
      "metadata": {
        "id": "ynyY_EFc2ylQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Metadata is \"data that provides information about other data\", but not the content of the data, such as the text of a message or the image itself. There are many distinct types of metadata, including: Descriptive metadata – the descriptive information about a resource. It is used for discovery and identification.**"
      ],
      "metadata": {
        "id": "M2G8kBRg-ATq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data in the Code and Docstring (code comments or the summary string) column needs to be cleaned of alphanumeric words, punctuation's, special symbols, single characters, etc. This is required to extract relevant words for training. In the code below, we show examples of how we clean the text from the sample JavaScript dataset."
      ],
      "metadata": {
        "id": "ONb0UZuF7OWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In programming, a docstring is a string literal specified in source code that is used, like a comment, to document a specific segment of code**\n"
      ],
      "metadata": {
        "id": "3nqmcDi6-ysr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fqc_s0rq5yh2"
      },
      "outputs": [],
      "source": [
        "import re  #The module re provides support for Perl-like regular expressions in Python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def clean_text(column):\n",
        "    for row in column:\n",
        "# Split CamelCase Characters like ConcatenationOperator to Concatenation Operator\n",
        "        row = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1',  str(row))).split()\n",
        "        row = ' '.join(row)\n",
        "# Replace tabs and newlines with a single space\n",
        "        row = re.sub(\"(\\\\t)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\\\r)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\\\n)\", \" \", str(row)).lower()\n",
        "# Remove the special characters and numbers \n",
        "        row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",.\\}`$\\{;@?~*!+=_\\//1234567890]\", \" \", str(row)).lower()\n",
        "# Remove Repeated words\n",
        "        row = re.sub(r\"\\\\b(\\\\w+)(?:\\\\W+\\\\1\\\\b)+\", \"\", str(row)).lower()\n",
        "# Remove punctuation at the end of a word\n",
        "        row = re.sub(\"(\\.\\s+)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\-\\s+)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\:\\s+)\", \" \", str(row)).lower()\n",
        "# Remove multiple spaces\n",
        "        row = re.sub(\"(\\s+)\", \" \", str(row)).lower()\n",
        "# Remove the single character (any character) between any two spaces\n",
        "        row = re.sub(\"(\\s+.\\s+)\", \" \", str(row)).lower()\n",
        "        yield row\n",
        "# Yield is a keyword in Python that is used to return from a function \n",
        "# without destroying the states of its local variable and when the function is called, the execution starts from the last yield statement"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**re.sub(pattern, repl, string, count=0, flags=0)**\n",
        "\n",
        "The first parameter, pattern, denotes the string/pattern that needs to be replaced.\n",
        "\n",
        "The second parameter, repl, denotes the string/pattern with which the pattern is replaced.\n",
        "\n",
        "The third parameter, string, denotes the string on which the re.sub() operation will be executed.\n",
        "\n",
        "The fourth parameter, count, denotes the number of replacements that should occur.\n",
        "\n",
        "The fifth parameter, flags, helps to shorten the code and has similar functions as that of a split operation.\n",
        "\n"
      ],
      "metadata": {
        "id": "lmJ2ivzkR8uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hence using the function clean_text, we preprocess the code and docstring (summary) columns of the sample dataset**"
      ],
      "metadata": {
        "id": "wTL_LrT06U8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CamelCase is the sequence of one or more than one words having the following properties: \n",
        " \n",
        "\n",
        "*  It is a concatenation of one or more words consisting of English letters.\n",
        "\n",
        "*   All letters in the first word are lowercase.\n",
        "\n",
        "\n",
        "*   For each of the subsequent words, the first letter is uppercase and rest of the letters are lowercase. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KSeza0f2SiNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_code = pd.read_csv('/content/drive/MyDrive/ALGO_ZENITH_BOOTCAMP_DATASET/javascript_Sample_Dataset.csv')\n",
        "#extract only the code and docstring columns\n",
        "df_code_p = df_code[[\"code\",\"docstring\"]]\n",
        "print (df_code_p[\"docstring\"][0])\n",
        "print (df_code_p.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJEKkRVE6UEe",
        "outputId": "fe61d0b9-5936-4cdf-d33d-fdc9d385e086"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find the next separator: space, parens, comma, colon, double-quote, dollar, brackets\n",
            "                                                code  \\\n",
            "0  function nextSeparator( str , runtime ) {\\n\\tv...   \n",
            "1  function parseFnKeyConst( str_ , runtime ) {\\n...   \n",
            "2  function(name, defaults) {\\n        _argValida...   \n",
            "3  function(scope) {\\n        if (!_argValidator....   \n",
            "4  function show(url) {\\n  const location = get('...   \n",
            "\n",
            "                                           docstring  \n",
            "0  Find the next separator: space, parens, comma,...  \n",
            "1  An identifier that is a function, a key or a c...  \n",
            "2  Configures global configuration settings, incl...  \n",
            "3  Returns a configuration object that is scoped ...  \n",
            "4                                               show  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call clean_text function\n",
        "processed_code= clean_text(df_code_p['code'])\n",
        "processed_summary = clean_text(df_code_p['docstring'])\n",
        "import spacy\n",
        "from time import time\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
        "# Process the text as batches, you may should the batchsize when you use the complete dataset, empirically can be set to 5000 for > 1,00,000 records\n",
        "code = [str(doc) for doc in nlp.pipe(processed_code, batch_size=50)]\n",
        "#_START_ and _END_ tokens are markers to understand start and end of summaries\n",
        "summary = [ str(doc) for doc in nlp.pipe(processed_summary, batch_size=50)]"
      ],
      "metadata": {
        "id": "nbuF9Vtv6ePU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, as all codes and docstrings are of different lengths, you can calculate the average length of pre-processed text in both the columns and decide on the length of the codes and doscstrings**\n",
        "Like first collect the length of all records in a columns (shown for the code column)"
      ],
      "metadata": {
        "id": "czkaXmYt6iQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_count=[]\n",
        "for sent in df_code_p['code']:\n",
        "    code_count.append(len(sent.split()))"
      ],
      "metadata": {
        "id": "XnhB1I2c6jmw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then plot a histogram to check the distribution"
      ],
      "metadata": {
        "id": "YJ8Fd2S475qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "histogram_df = pd.DataFrame()\n",
        "histogram_df['code'] = code_count\n",
        "histogram_df.hist(bins = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "nWiyt-Yz735O",
        "outputId": "d2a891b3-91a9-40b4-8a82-bd66c1e54cc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example based on the distribution across bins, we see that around 80\\% of the codes lie within the length of 200, so we can set the maximum length as 200. Summaries are usually shorter in length.\n",
        "\n",
        "We set"
      ],
      "metadata": {
        "id": "9uAY3gYq6u81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_code_len = 100\n",
        "max_summary_len =25\n",
        "# Extract the codes and summaries within the maximum length\n",
        "import numpy as np\n",
        "cleaned_code = np.array(df_code_p['code'])\n",
        "cleaned_summary= np.array(df_code_p['docstring'])\n",
        "short_text = []\n",
        "short_summary = []\n",
        "for i in range(len(cleaned_code)):\n",
        "  if len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_code[i].split()) <= max_code_len:\n",
        "    short_text.append(cleaned_code[i])\n",
        "    short_summary.append(cleaned_summary[i])\n",
        "    post_code = pd.DataFrame({'code': short_text,'summary': short_summary})\n",
        "    post_code.head(100)\n",
        "#apply start and end markers\n",
        "post_code['summary'] = post_code['summary'].apply(lambda x: 'sostok ' + x \\\n",
        "+ ' eostok')\n",
        "post_code.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RoLNjddj6v_k",
        "outputId": "973086fe-f8fa-4099-8b36-dccb2e5e1578"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                code  \\\n",
              "0  function show(url) {\\n  const location = get('...   \n",
              "1  function(_url,_href){\\n            if (!_url) ...   \n",
              "2  function(_config){\\n            if (!_config) ...   \n",
              "3  function(_action,_name){\\n            var _am ...   \n",
              "4  function(_node,_message){\\n            var _mo...   \n",
              "\n",
              "                                    summary  \n",
              "0                        sostok show eostok  \n",
              "1  sostok check event need delegated eostok  \n",
              "2              sostok regist rewrite eostok  \n",
              "3              sostok regist actions eostok  \n",
              "4                sostok send message eostok  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fe5f41a-8d8a-4398-8d57-f02a3de184b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>function show(url) {\\n  const location = get('...</td>\n",
              "      <td>sostok show eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>function(_url,_href){\\n            if (!_url) ...</td>\n",
              "      <td>sostok check event need delegated eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>function(_config){\\n            if (!_config) ...</td>\n",
              "      <td>sostok regist rewrite eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>function(_action,_name){\\n            var _am ...</td>\n",
              "      <td>sostok regist actions eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>function(_node,_message){\\n            var _mo...</td>\n",
              "      <td>sostok send message eostok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fe5f41a-8d8a-4398-8d57-f02a3de184b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fe5f41a-8d8a-4398-8d57-f02a3de184b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fe5f41a-8d8a-4398-8d57-f02a3de184b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisation - II"
      ],
      "metadata": {
        "id": "Xf6XUOxEAu3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will be using the fit_on_texts tokeniser from keras**\n",
        "\n",
        "The fit_on_texts method is a part of Keras tokenizer class which is used to update the internal vocabulary for the texts list. We need to call be before using other methods of texts_to_sequences or texts_to_matrix.\n",
        "\n",
        "The object returned by fit_on_texts can be used to derive more information by using the following attributes (text from the keras tokeniser tutorial)-\n",
        "\n",
        "**word_counts** : It is a dictionary of words along with the counts.\n",
        "\n",
        "**word_docs** : Again a dictionary of words, this tells us how many documents contain this word\n",
        "\n",
        "**word_index** : In this dictionary, we have unique integers assigned to each word.\n",
        "\n",
        "**document_count**: This integer count will tell us the total number of documents used for fitting the tokenizer.\n"
      ],
      "metadata": {
        "id": "90NlDsOUTUdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "t  = Tokenizer()\n",
        "#This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary)\n",
        "#or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...\n",
        "\n",
        "fit_text = 'Machine Learning'\n",
        "\n",
        "t.fit_on_texts(fit_text)\n",
        "\n",
        "print(\"Count of characters:\",t.word_counts)\n",
        "print(\"Length of text:\",t.document_count)\n",
        "print(\"Character index\",t.word_index)\n",
        "print(\"Frequency of characters:\",t.word_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOLXCWq6OHXo",
        "outputId": "c4c82b78-05da-4bcb-ec2f-e25f93a99255"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of characters: OrderedDict([('m', 1), ('a', 2), ('c', 1), ('h', 1), ('i', 2), ('n', 3), ('e', 2), ('l', 1), ('r', 1), ('g', 1)])\n",
            "Length of text: 16\n",
            "Character index {'n': 1, 'a': 2, 'i': 3, 'e': 4, 'm': 5, 'c': 6, 'h': 7, 'l': 8, 'r': 9, 'g': 10}\n",
            "Frequency of characters: defaultdict(<class 'int'>, {'m': 1, 'a': 2, 'c': 1, 'h': 1, 'i': 2, 'n': 3, 'e': 2, 'l': 1, 'r': 1, 'g': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We use the pre-processed codes and summaries that are within the maximum length and divide into train and test sets**"
      ],
      "metadata": {
        "id": "_V7XrtYJTx8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(\n",
        "np.array(post_code[\"code\"]),\n",
        "np.array(post_code[\"summary\"]),\n",
        "test_size=0.15,\n",
        "random_state=0,\n",
        "shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "3SZVeHYLONVM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next we fit the tokenizer on the code sequences**"
      ],
      "metadata": {
        "id": "a12ytcUdT30Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will not consider infrequent words in the vocabulary, as it may add noise\n",
        "# Hence we omit words which occur only two times ( you can change the threshold to 5 in case of larger datasets)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Prepare a tokenizer on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "threshold = 2\n",
        "cnt_infrequent = 0\n",
        "total_cnt = 0\n",
        "for key, value in x_tokenizer.word_counts.items():\n",
        "    total_cnt = total_cnt + 1\n",
        "    if value < threshold:\n",
        "       cnt_infrequent = cnt_infrequent + 1\n",
        "print(\"% of not frequent words in vocabulary: \", (cnt_infrequent / total_cnt) * 100)\n",
        "# Remove the infrequent words\n",
        "x_tokenizer = Tokenizer(num_words = total_cnt - cnt_infrequent)\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "# Convert the code sequences to integer sequences (integer numbers ranging from 1 to the maximum vocab sizes)\n",
        "x_train_seqs = x_tokenizer.texts_to_sequences(x_train)\n",
        "x_validation_seqs = x_tokenizer.texts_to_sequences(x_validation)\n",
        "# printing the integer sequences\n",
        "print (x_train_seqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV8WEcmXOzHl",
        "outputId": "a0a5f161-d513-4cb7-f4d9-d2b5dd0f30d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of not frequent words in vocabulary:  44.2159383033419\n",
            "[[3, 129, 130, 2, 20, 73, 20, 131, 132, 132, 131, 129, 38, 130, 23, 9, 9], [3, 39, 74, 24, 39, 39, 2, 21, 133, 39, 39, 39, 4, 21, 19, 21, 39, 3, 134, 4, 134, 74, 24], [3, 135, 5, 14, 28, 21, 55, 135, 3, 75, 2, 75, 4, 2, 14, 14, 75, 40, 14, 136, 14, 75, 4, 14], [3, 137, 138, 56, 1, 35, 137, 138, 1, 56, 56], [3, 46, 2, 29, 46, 47, 1, 139, 46, 2, 1, 48, 4, 76, 5, 140, 1, 1, 100, 1, 100, 141, 1, 1, 48, 1, 100, 19, 1, 140, 4, 49], [3, 15, 101, 102, 36, 5, 77, 15, 142, 143, 2, 101, 15, 102, 36, 30, 25, 144, 145, 146, 147, 41, 103, 148, 3, 78, 149, 42, 150, 151, 152, 153, 154, 155, 156, 157, 78, 158, 77, 9, 102, 159, 101, 104, 15, 15, 19, 77, 79, 104, 15, 15, 141, 77, 79, 160, 15, 23, 79, 57, 161, 14, 15, 36, 36], [3, 10, 2, 10, 4, 1, 10, 56, 80, 10, 41, 26, 21, 55, 3, 6, 2, 10, 6, 4, 1, 10, 6, 10, 6, 10, 6, 1], [3, 1, 162, 49, 1, 162, 55, 1, 58, 1, 1, 31, 103, 59, 1, 55, 1, 58, 1, 1], [3, 81, 5, 163, 81, 1, 10, 81, 1, 10, 164, 163, 3, 10, 1, 10, 50, 82, 1, 4, 1], [3, 83, 5, 6, 84, 6, 26, 1, 10, 2, 1, 10, 105, 6, 1, 10, 6, 1, 165, 6, 83, 4, 1], [3, 2, 26, 16, 2, 26, 16, 20, 57, 51, 60, 43, 166, 16, 20, 166, 2, 26, 16, 20, 57, 51, 60, 43, 106, 16, 20, 106, 2, 26, 16, 20, 84, 5, 6, 26, 16, 20, 167, 57, 51, 43, 106, 9, 6, 16, 20, 167, 6], [3, 19, 5, 6, 84, 6, 26, 19, 2, 19, 105, 6, 1, 165, 6, 19, 6, 4, 1], [3, 27, 1, 27, 27, 1, 49, 25, 1, 168], [3, 169, 2, 29, 1, 170, 47, 1, 170, 40, 2, 29, 1, 171, 47, 1, 171, 40, 2, 29, 1, 172, 47, 1, 172, 40, 2, 29, 1, 173, 47, 1, 173, 40, 30, 35, 25, 31, 169], [3, 174, 5, 85, 174, 9, 9, 5, 61, 85, 175, 107, 85, 108, 61, 61, 61, 85, 175, 4, 61], [3, 37, 27, 5, 44, 27, 44, 107, 37, 2, 37, 176, 44, 177, 37, 27, 37, 37], [3, 52, 52, 52, 178, 49, 52, 1, 86, 52, 4, 52], [3, 87, 21, 164, 87, 3, 22, 2, 22, 109, 179, 110, 180, 87, 5, 11, 181, 22, 2, 179, 182, 183, 11, 22, 4, 32, 80, 11, 2, 180, 182, 183, 11, 22, 4, 32, 80, 11, 4, 32, 20, 31, 22, 22], [3, 19, 5, 6, 84, 6, 26, 19, 2, 19, 105, 6, 1, 6, 19, 6, 4, 1], [3, 11, 2, 11, 24, 32, 26, 11, 11, 111, 4, 76, 4, 29, 11, 111, 11, 111], [3, 62, 2, 133, 62, 4, 62, 184, 185, 82, 40, 2, 62, 4, 62, 27], [3, 63, 186, 5, 6, 186, 9, 9, 32, 6, 32, 6, 5, 8, 63, 8, 112, 187, 63, 22, 107, 32, 6, 8, 8, 9, 9, 8, 32, 6, 8, 63, 63, 8, 8], [3, 64, 88, 2, 64, 4, 5, 53, 50, 41, 64, 1, 53, 5, 89, 1, 53, 22, 88, 53, 88, 4, 1, 1, 89], [3, 33, 17, 188, 2, 33, 8, 17, 8, 2, 188, 5, 12, 35, 25, 65, 12, 33, 12, 17, 30, 12, 81, 5, 14, 8, 17, 8, 33, 8, 66, 17, 66, 17, 66, 33, 66, 65, 17, 65, 17, 65, 33, 65, 51, 33, 51, 17, 51, 2, 33, 67, 17, 67, 14, 67, 33, 67, 17, 67, 4, 14], [3, 1, 68, 90, 189, 12, 43, 190, 91, 191, 113, 92, 192, 12, 1, 68, 69, 12, 1, 193, 69, 90, 194, 195, 1, 34, 195, 1, 28, 2, 1, 34, 196, 1, 1, 34, 197, 12, 43, 53, 91, 12, 1, 68, 1, 114, 1, 34, 197, 12, 43, 53, 91, 192, 12, 1, 114, 69, 1, 34, 196, 198, 1, 68, 198, 1, 114, 90, 199, 115, 43, 190, 91, 191, 113, 92, 115, 1, 68, 69, 115, 1, 193, 69, 194, 189, 200, 199], [3, 181, 45, 5, 11, 2, 29, 45, 109, 11, 45, 109, 11, 22, 112, 45, 116, 45, 116, 184, 45, 116, 9, 9, 112, 187, 45, 22, 4, 11], [3, 117, 118, 1, 201, 28, 119, 1, 117, 117, 1, 118, 118, 1, 28, 1, 23, 1, 82, 1, 23, 1, 76, 1, 1, 23], [3, 37, 27, 5, 44, 27, 44, 37, 3, 60, 2, 60, 176, 44, 177, 60, 27], [3, 70, 1, 201, 28, 119, 2, 13, 54, 30, 35, 25, 13, 54, 93, 31, 42, 94, 95, 13, 70, 2, 13, 38, 30, 35, 25, 13, 38, 93, 31, 42, 94, 95, 13, 70, 2, 13, 54, 202, 13, 54, 203, 13, 54, 204, 30, 35, 25, 13, 54, 92, 202, 203, 110, 204, 93, 31, 42, 94, 95, 13, 70, 2, 13, 38, 205, 13, 38, 206, 30, 35, 25, 13, 38, 92, 205, 110, 206, 93, 31, 42, 94, 95, 13, 70], [3, 96, 24, 24, 24, 24, 24, 5, 96, 24, 74, 32, 74, 87, 2, 96, 30, 35, 25, 66, 9, 24, 4, 96], [3, 46, 2, 29, 46, 47, 1, 139, 46, 2, 1, 48, 1, 48, 1, 48, 55, 1, 1, 48, 23, 2, 1, 1, 49, 4, 76, 1, 4, 49], [3, 120, 73, 120, 178, 207, 42, 185, 207, 5, 208, 168, 119, 120, 208], [3, 209, 97, 121, 97, 19, 122, 56, 5, 34, 97, 122, 159, 29, 34, 104, 97, 122, 34, 79, 160, 209, 34], [3, 123, 5, 16, 210, 123, 124, 98, 86, 123, 211, 98, 86, 16, 2, 124, 16, 4, 5, 7, 99, 124, 59, 7, 108, 16, 7, 99, 7, 17, 16, 212, 7, 108, 16, 7, 211, 7, 59, 136, 212, 28, 7, 17], [3, 125, 126, 36, 5, 127, 128, 15, 12, 23, 142, 143, 2, 125, 36, 30, 25, 144, 145, 146, 147, 128, 126, 38, 41, 126, 23, 41, 103, 148, 3, 78, 149, 42, 150, 151, 152, 153, 154, 155, 156, 157, 78, 158, 127, 9, 125, 15, 127, 128, 73, 20, 9, 9, 15, 200, 98, 15, 23, 12, 98, 57, 161, 14, 15, 12, 12, 36, 36], [3, 71, 8, 5, 72, 1, 10, 72, 41, 7, 18, 44, 121, 5, 7, 18, 71, 8, 8, 82, 2, 21, 71, 7, 71, 7, 7, 18, 71, 59, 41, 18, 2, 21, 213, 18, 18, 3, 89, 83, 1, 214, 89, 215, 28, 99, 83, 58, 1, 18, 40, 2, 21, 216, 18, 18, 18, 23, 3, 7, 5, 14, 7, 59, 2, 21, 213, 14, 1, 214, 14, 215, 28, 99, 7, 28, 58, 1, 80, 18, 31, 210, 2, 21, 216, 18, 7, 2, 72, 7, 1, 7, 1, 58, 1, 72, 7, 72, 7, 8, 18], [3, 64, 90, 50, 86, 2, 50, 73, 113, 31, 50, 121, 4, 50, 88, 64]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad zero upto maximum length\n",
        "x_train = pad_sequences(x_train_seqs,  maxlen=max_code_len, padding='post')\n",
        "x_validation = pad_sequences(x_validation_seqs, maxlen=max_code_len, padding='post')\n",
        "# Size of vocabulary (+1 for padding token)\n",
        "x_voc = x_tokenizer.num_words + 1\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNxoSrNmO5ok",
        "outputId": "c3ff407a-f960-4f7f-960a-e01d9a32c1fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary in X = 218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Similarly we fit the tokenizer on the summary sequences**\n",
        "\n"
      ],
      "metadata": {
        "id": "7XI1tyWAVDkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "threshold = 2\n",
        "cnt_infrequent = 0\n",
        "total_cnt = 0\n",
        "for key, value in y_tokenizer.word_counts.items():\n",
        "    total_cnt = total_cnt + 1\n",
        "    if value < threshold:\n",
        "        cnt_infrequent = cnt_infrequent + 1\n",
        "y_tokenizer = Tokenizer(num_words = total_cnt - cnt_infrequent)\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "y_train_seqs = y_tokenizer.texts_to_sequences(y_train)\n",
        "y_validation_seqs = y_tokenizer.texts_to_sequences(y_validation)\n",
        "y_train = pad_sequences(y_train_seqs,  maxlen=max_summary_len, padding='post')\n",
        "y_validation = pad_sequences(y_validation_seqs, maxlen=max_summary_len, padding='post')\n",
        "y_voc = y_tokenizer.num_words + 1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O4xSPDTPEUQ",
        "outputId": "b12ddc12-e081-4145-bcc4-74c1301d01aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary in Y = 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(len(x_validation))\n",
        "print(len(y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OhULym6PKRb",
        "outputId": "84ab85cf-84eb-4d9e-a3a8-522a5bbec262"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n",
            "37\n",
            "7\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((x_train[0]))\n",
        "print((y_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpTfcltHPRRr",
        "outputId": "1cec831e-3349-46db-de07-54489b1a82d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  3 129 130   2  20  73  20 131 132 132 131 129  38 130  23   9   9   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Decoder Architecture and Training — III"
      ],
      "metadata": {
        "id": "6zvxsPZedQFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
        "Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "Hnc3Nt-0dTt-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the encoder decoder architecture"
      ],
      "metadata": {
        "id": "TTOh7TOidkkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 300\n",
        "embedding_dim = 200\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_code_len, ))\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim,\n",
        "trainable=True)(encoder_inputs)\n",
        "# Encoder LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
        "return_state=True, dropout=0.4,\n",
        "recurrent_dropout=0.4)\n",
        "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
        "# Encoder LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
        "return_state=True, dropout=0.4,\n",
        "recurrent_dropout=0.4)\n",
        "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
        "# Encoder LSTM 3\n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
        "return_sequences=True, dropout=0.4,\n",
        "recurrent_dropout=0.4)\n",
        "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "# Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
        "return_state=True, dropout=0.4,\n",
        "recurrent_dropout=0.2)\n",
        "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
        "decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5lNa0FLdm5L",
        "outputId": "4acdeb65-51d2-438c-e3a6-6b085ab59329"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 200)     43600       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 100, 300),   601200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 100, 300),   721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    12200       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 100, 300),   721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 61)    18361       ['lstm_3[0][0]']                 \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,718,961\n",
            "Trainable params: 2,718,961\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "history = model.fit(\n",
        "[x_train, y_train[:, :-1]],\n",
        "y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
        "epochs=50,\n",
        "callbacks=[es],\n",
        "batch_size=128,\n",
        "validation_data=([x_validation, y_validation[:, :-1]],\n",
        "y_validation.reshape(y_validation.shape[0], y_validation.shape[1], 1)[:\n",
        ", 1:]),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9o9iL5Md0ST",
        "outputId": "11ea1241-1c8b-4395-bd4b-a4af14a82cae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 18s 18s/step - loss: 4.1241 - val_loss: 3.7467\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 3.7872 - val_loss: 1.0454\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.4359 - val_loss: 3.4806\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 3.4830 - val_loss: 1.3960\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration**"
      ],
      "metadata": {
        "id": "99Kz4dlEsjZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
        "state_h, state_c])\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
        "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
        "decoder_hidden_state_input = Input(shape=(max_code_len, latent_dim))\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "VfyCg-4GeIPc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The code for generating the decoded sequence**"
      ],
      "metadata": {
        "id": "vlIAIlqH8F8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "# Encode the input as state vectors.\n",
        "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
        "# Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1))\n",
        "# Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
        "        + [e_out, e_h, e_c])\n",
        "# Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    if sampled_token != 'eostok':\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "# Exit condition: either hit max length or find the stop word.\n",
        "    if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
        ">= max_summary_len - 1:\n",
        "       stop_condition = True\n",
        "# Update the target sequence (of length 1)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "# Update internal states\n",
        "    (e_h, e_c) = (h, c)\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "F-j9d-CS8ZUQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also we define two functions to generate string sequences from integer sequences which we will use to retrieve the code and summary sequences from the tokenized integer sequences"
      ],
      "metadata": {
        "id": "rbiQs4CY73_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0 and i != target_word_index['sostok'] and i \\\n",
        "        != target_word_index['eostok']:\n",
        "             newString = newString + reverse_target_word_index[i] + ' '\n",
        "    return newString\n",
        "# To convert sequence to text\n",
        "def seq2text(input_seq):\n",
        "     newString = ''\n",
        "     for i in input_seq:\n",
        "      if i != 0:\n",
        "             newString = newString + reverse_source_word_index[i] + ' '\n",
        "     return newString"
      ],
      "metadata": {
        "id": "mvBsOoUN79mQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finally predict for some of the sequences**"
      ],
      "metadata": {
        "id": "U-TjvIoj7s6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 19):\n",
        "    print ('Code:', seq2text(x_train[i]))\n",
        "    print ('Original summary:', seq2summary(y_train[i]))\n",
        "    print ('Predicted summary:', decode_sequence(x_train[i].reshape(1,max_code_len)))\n",
        "    print ('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldpeyNHp7xoR",
        "outputId": "ae9b57d0-e7db-410a-f6ba-026a4da8fa34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: function which what if log console log n s s n which json what null ' ' \n",
            "Original summary: \n"
          ]
        }
      ]
    }
  ]
}